{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from Module.showInferensModel import load_labels, plot_image_with_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_BEST = '../Weightts/yolo11s_210_split_aug.pt'\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# PATH_DATASET = './DataSet/MyData/dataset.yaml'\n",
    "PATH_DATASET = './DataSet/SplitData/dataset.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(PATH_BEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.23  Python-3.10.0 torch-2.5.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12287MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11s summary (fused): 238 layers, 9,413,187 parameters, 0 gradients, 21.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Nsu\\SearchPersonAI\\AI\\DataSet\\SplitData\\Test2\\labels.cache... 5159 images, 4832 backgrounds, 0 corrupt: 100%|██████████| 5159/5159 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 323/323 [00:32<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5159        440      0.898      0.861       0.91      0.691\n",
      "Speed: 0.2ms preprocess, 5.2ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Saving runs\\detect\\val\\predictions.json...\n",
      "Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.val(data=PATH_DATASET, split='test', imgsz=640, conf=0.3, save_json=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics Dictionary: {'metrics/precision(B)': 0.8981042654028436, 'metrics/recall(B)': 0.8613636363636363, 'metrics/mAP50(B)': 0.9098270833561759, 'metrics/mAP50-95(B)': 0.6906904208492539, 'fitness': 0.7126040870999462}\n"
     ]
    }
   ],
   "source": [
    "# Доступ к числовым метрикам\n",
    "metrics = results.results_dict\n",
    "print(f\"Metrics Dictionary: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8981\n",
      "Recall: 0.8614\n",
      "mAP@0.5: 0.9098\n",
      "mAP@0.5:0.95: 0.6907\n",
      "Fitness: 0.7126\n",
      "f1: 0.8794\n"
     ]
    }
   ],
   "source": [
    "# Извлекаем числовые значения метрик\n",
    "precision = results.results_dict['metrics/precision(B)']\n",
    "recall = results.results_dict['metrics/recall(B)']\n",
    "map50 = results.results_dict['metrics/mAP50(B)']\n",
    "map50_95 = results.results_dict['metrics/mAP50-95(B)']\n",
    "fitness = results.results_dict['fitness']\n",
    "\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Округляем и выводим метрики\n",
    "print(f\"Precision: {precision:.4f}\") # Точность\n",
    "print(f\"Recall: {recall:.4f}\") # Полнота\n",
    "print(f\"mAP@0.5: {map50:.4f}\") # mAP@0.5\n",
    "print(f\"mAP@0.5:0.95: {map50_95:.4f}\") # mAP@0.5:0.95\n",
    "print(f\"Fitness: {fitness:.4f}\")\n",
    "print(f\"f1: {f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 \n",
    "\n",
    "Precision: 0.9525\n",
    "Recall: 0.6430\n",
    "mAP@0.5: 0.8043\n",
    "mAP@0.5:0.95: 0.5005\n",
    "Fitness: 0.5309\n",
    "f1: 0.7678\n",
    "\n",
    "Точность (95.25%) высокая: модель редко делает ложные предсказания.\n",
    "\n",
    "Полнота (64.3%) средняя: модель пропускает значительное количество объектов.\n",
    "\n",
    "mAP@0.5 (80.43%) хорошая: модель уверенно детектирует объекты с умеренным перекрытием.\n",
    "\n",
    "mAP@0.5:0.95 (50.05%) средняя: модель хуже справляется с точным определением границ объектов.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Precision: 0.9314\n",
    "Recall: 0.7409\n",
    "mAP@0.5: 0.8442\n",
    "mAP@0.5:0.95: 0.6304\n",
    "Fitness: 0.6518\n",
    "f1: 0.8253"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ИСТОРИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- 1 yolov8n 100\n",
    "# Precision: 0.9525\n",
    "# Recall: 0.6430\n",
    "# mAP@0.5: 0.8043\n",
    "# mAP@0.5:0.95: 0.5005\n",
    "# Fitness: 0.5309\n",
    "# f1: 0.7678\n",
    "\n",
    "# ---------------------------- 2 yolov8n 100 split\n",
    "# Precision: 0.9525\n",
    "# Recall: 0.6430\n",
    "# mAP@0.5: 0.8043\n",
    "# mAP@0.5:0.95: 0.5005\n",
    "# Fitness: 0.5309\n",
    "# f1: 0.7678\n",
    "\n",
    "# ---------------------------- 3 yolov8s 100 split aug 1\n",
    "# Precision: 0.9314\n",
    "# Recall: 0.7409\n",
    "# mAP@0.5: 0.8442\n",
    "# mAP@0.5:0.95: 0.6304\n",
    "# Fitness: 0.6518\n",
    "# f1: 0.8253\n",
    "\n",
    "# ---------------------------- 4 yolov8s_200_split_aug\n",
    "# model.train(data=PATH_DATASET,\n",
    "#             augment=True,\n",
    "#             single_cls=True,\n",
    "#             copy_paste=0.2,\n",
    "#             max_det=30,\n",
    "#             iou=0.6,\n",
    "#             close_mosaic=10,\n",
    "#             patience=30,\n",
    "#             batch=18, \n",
    "#             epochs=210, \n",
    "#             imgsz=640, \n",
    "#             mixup=0.7, \n",
    "#             flipud=0.5, \n",
    "#             shear=0.3, \n",
    "#             degrees=0.3,\n",
    "#             translate=0.2,\n",
    "#             resume=True,\n",
    "#             device=DEVICE)\n",
    "\n",
    "# Precision: 0.9424\n",
    "# Recall: 0.8273\n",
    "# mAP@0.5: 0.9118\n",
    "# mAP@0.5:0.95: 0.6998\n",
    "# Fitness: 0.7210\n",
    "# f1: 0.8811\n",
    "\n",
    "\n",
    "# # ---------------------------- 5 yolo11s_210_split_aug\n",
    "# model.train(data=PATH_DATASET,\n",
    "#             augment=True,\n",
    "#             single_cls=True,\n",
    "#             copy_paste=0.2,\n",
    "#             max_det=30,\n",
    "#             iou=0.6,\n",
    "#             close_mosaic=10,\n",
    "#             patience=30,\n",
    "#             batch=18, \n",
    "#             epochs=210, \n",
    "#             imgsz=640, \n",
    "#             mixup=0.7, \n",
    "#             flipud=0.5, \n",
    "#             shear=0.3, \n",
    "#             degrees=0.3,\n",
    "#             translate=0.2,\n",
    "#             resume=True,\n",
    "#             device=DEVICE)\n",
    "\n",
    "# Precision: 0.8981\n",
    "# Recall: 0.8614\n",
    "# mAP@0.5: 0.9098\n",
    "# mAP@0.5:0.95: 0.6907\n",
    "# Fitness: 0.7126\n",
    "# f1: 0.8794\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
