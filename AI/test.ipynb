{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from Module.showInferensModel import load_labels, plot_image_with_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_BEST = '../Weightts/120.pt'\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# PATH_DATASET = './DataSet/MyData/dataset.yaml'\n",
    "PATH_DATASET = './DataSet/SplitData/dataset.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(PATH_BEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.23  Python-3.10.0 torch-2.5.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12287MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Nsu\\SearchPersonAI\\AI\\DataSet\\SplitData\\Test2\\labels.cache... 5159 images, 4832 backgrounds, 0 corrupt: 100%|██████████| 5159/5159 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 323/323 [00:16<00:00, 19.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5159        440          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.2ms preprocess, 2.4ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.val(data=PATH_DATASET, split='test', imgsz=640, conf=0.3, save_json=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics Dictionary: {'metrics/precision(B)': 0.0, 'metrics/recall(B)': 0.0, 'metrics/mAP50(B)': 0.0, 'metrics/mAP50-95(B)': 0.0, 'fitness': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Доступ к числовым метрикам\n",
    "metrics = results.results_dict\n",
    "print(f\"Metrics Dictionary: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m map50_95 \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mresults_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics/mAP50-95(B)\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m fitness \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mresults_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 8\u001b[0m f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrecall\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrecall\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Округляем и выводим метрики\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# Точность\u001b[39;00m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "# Извлекаем числовые значения метрик\n",
    "precision = results.results_dict['metrics/precision(B)']\n",
    "recall = results.results_dict['metrics/recall(B)']\n",
    "map50 = results.results_dict['metrics/mAP50(B)']\n",
    "map50_95 = results.results_dict['metrics/mAP50-95(B)']\n",
    "fitness = results.results_dict['fitness']\n",
    "\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Округляем и выводим метрики\n",
    "print(f\"Precision: {precision:.4f}\") # Точность\n",
    "print(f\"Recall: {recall:.4f}\") # Полнота\n",
    "print(f\"mAP@0.5: {map50:.4f}\") # mAP@0.5\n",
    "print(f\"mAP@0.5:0.95: {map50_95:.4f}\") # mAP@0.5:0.95\n",
    "print(f\"Fitness: {fitness:.4f}\")\n",
    "print(f\"f1: {f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 \n",
    "\n",
    "Precision: 0.9525\n",
    "Recall: 0.6430\n",
    "mAP@0.5: 0.8043\n",
    "mAP@0.5:0.95: 0.5005\n",
    "Fitness: 0.5309\n",
    "f1: 0.7678\n",
    "\n",
    "Точность (95.25%) высокая: модель редко делает ложные предсказания.\n",
    "\n",
    "Полнота (64.3%) средняя: модель пропускает значительное количество объектов.\n",
    "\n",
    "mAP@0.5 (80.43%) хорошая: модель уверенно детектирует объекты с умеренным перекрытием.\n",
    "\n",
    "mAP@0.5:0.95 (50.05%) средняя: модель хуже справляется с точным определением границ объектов.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Precision: 0.9314\n",
    "Recall: 0.7409\n",
    "mAP@0.5: 0.8442\n",
    "mAP@0.5:0.95: 0.6304\n",
    "Fitness: 0.6518\n",
    "f1: 0.8253"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
